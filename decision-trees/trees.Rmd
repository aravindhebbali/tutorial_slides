---
output: _output.yaml
---

## {data-background="img/regex_cover_image.png"}

## Connect With Us

<hr>

- Website     (https://www.rsquaredacademy.com/)
- Free Online R Courses   (https://rsquared-academy.thinkific.com/)
- R Packages  (https://pkgs.rsquaredacademy.com)
- Shiny Apps  (https://apps.rsquaredacademy.com)
- Blog        (https://blog.rsquaredacademy.com)
- GitHub      (https://github.com/rsquaredacademy)
- YouTube     (https://www.youtube.com/user/rsquaredin/)
- Twitter     (https://twitter.com/rsquaredacademy)
- Facebook    (https://www.facebook.com/rsquaredacademy/)
- Linkedin    (https://in.linkedin.com/company/rsquared-academy)

## Resources

<hr>

- <a href="https://slides.rsquaredacademy.com/decision-trees/trees.html" target="_blank">Slides</a>
- <a href="https://github.com/rsquaredacademy-education/online-courses/tree/master/decision-trees-in-r" target="_blank">Code & Data</a>
- <a href="https://rstudio.cloud/project/356612" target="_blank">RStudio Cloud</a>

## {data-background="img/ws_agenda.png"}

<br>
<br>
<br>
<br>

- what is a decision tree?


## {data-background="img/ws_section_intro.png"}

## What?

<hr>

## Classification

<hr>

## Scoring

<hr>

## Estimation

<hr>

## Finding the Split

<hr>

## Splitting on Numeric Variable

<hr>

## Splitting on Categorical Variable

<hr>

## Handling Missing Values

<hr>

## Growing the Tree

<hr>

## Effectiveness of the Tree

<hr>

## Choosing the best Split

<hr>

- Gini
- Entropy
- Information Gain Ratio
- Chi Square Test
- Reduction in Variance
- F Test

## Gini 

<hr>

## Entropy

<hr>

## Information Gain Ratio

<hr>

## Chi-Square Test

<hr>

## Reduction in Variance

<hr>

## F Test

<hr>

## Pruning

<hr>

## Extracting Rules

<hr>

## Cost

<hr>

## Visualization

<hr>
 
## Libraries

<hr>

```{r install, eval=TRUE, message=FALSE, warning=FALSE}
library(dplyr)
library(rpart)        # recursive partitioning
library(rpart.plot)   # visualization
library(rattle)       # visualization
library(RColorBrewer) # plot colors
library(magrittr)     # pipes
library(caret)        # confusion matrix, cross validation, bagging
library(rsample)      # data partition
library(parsnip)      # unified interface
library(ROCR)         # roc curves
library(yardstick)    # roc curves & classification matrix
```

## Data

<hr>

```{r read_data, message=FALSE}
```

## Data Partitioning

<hr>

```{r data_split}
set.seed(123)
iris_split <- initial_split(iris, prop = .7)
iris_train <- training(iris_split)
iris_test  <- testing(iris_split)
```

## Grow Tree

<hr>

```{r grow_tree}
model <- rpart(Species ~ ., data = iris_train)
model
```

## Visualize 

<hr>

```{r viz_tree, fig.align="center"}
plot(model)
text(model, digits = 3)
```

## Tree Summary

<hr>

```{r tree_summary}
summary(model)
```

## Complexity Parameter

<hr>

```{r printcp}
printcp(model)
```

## Plot Complexity Parameter

<hr>

```{r plotcp, fig.align='center'}
plotcp(model)
```

## Visualize Tree

<hr>

```{r prp_tree, fig.align='center'}
prp(model)
```

## Prune Tree

<hr>

```{r findcp, echo=FALSE}
cp_table <-
  model %>%
  use_series(cptable) %>%
  as.data.frame()

xerror_min_index <-
  cp_table %>%
  pull(xerror) %>%
  which.min()

cp_min <-
  cp_table %>%
  pull(CP) %>%
  magrittr::extract(xerror_min_index)
```

```{r prune_tree}
pruned_model <- prune(model, cp = cp_min)
pruned_model
```

## Fancy Plot

<hr>

```{r fancy_plot, fig.align='center'}
fancyRpartPlot(pruned_model, uniform = TRUE)
```

## Predict

<hr>

```{r predict_tree}
predictions <- predict(model, iris_test, type="class")
predictions
```

## Confusion Matrix

<hr>

```{r cm_tree}
confusionMatrix(predictions, iris_test$Species)
```

## Summary

<hr>

## References

<hr>

## {data-background="img/thankyou.png"}
